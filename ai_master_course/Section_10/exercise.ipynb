{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"exercise.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"K74mqS_L8nq4","colab_type":"text"},"source":["# 演習\n","GANにバッチ正規化を導入しましょう。  \n","中間層におけるデータのばらつきを抑えることで、結果にどのような影響が及ぶのか確認してみましょう。"]},{"cell_type":"markdown","metadata":{"id":"fefMYANgW6UK","colab_type":"text"},"source":["## バッチ正規化とは？\n","中間層のある時点でバッチごとに平均値を0、標準偏差を1にします。  \n","これより、中間層でデータが散らばることを防ぎ、学習を効率化します。  \n","Kerasでは、バッチ正規化を層として簡単に実装することができます。  \n","\n","バッチ正規化は以下の式で表されます。  \n","\n","$$Y = \\gamma \\frac{X-\\mu}{\\sigma} + \\beta$$\n","\n","$\\mu$がバッチ内の平均値、$\\sigma$がバッチ内の標準偏差、$X$と$Y$がバッチ正規化層の入出力、$\\gamma$と$\\beta$はバッチ正規化層において学習するパラメータです。  \n","\n","GANは通常のニューラルネットワークと比較して学習方法が複雑なため、学習が不安定になりがちです。  \n","そのため、バッチ正規化による中間層の安定化がよく試みられます。  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"AAYDnNlPJ46Z","colab_type":"text"},"source":["## 訓練用データの用意\n","GANに用いる訓練用のデータを用意します。   "]},{"cell_type":"code","metadata":{"id":"EcKpe2k38bax","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt \n","from keras.datasets import mnist\n","\n","(x_train, t_train), (x_test, t_test) = mnist.load_data()  # MNISTの読み込み\n","print(x_train.shape, x_test.shape)  # 28x28の手書き文字画像が6万枚\n","\n","# 各ピクセルの値を-1から1の範囲に収める\n","x_train = x_train / 255 * 2 - 1\n","x_test = x_test / 255 * 2 - 1\n","\n","# 手書き文字画像の表示\n","plt.imshow(x_train[0].reshape(28, 28), cmap=\"gray\")\n","plt.title(t_train[0])\n","plt.show() \n","\n","# 一次元に変換する\n","x_train = x_train.reshape(x_train.shape[0], -1)\n","x_test = x_test.reshape(x_test.shape[0], -1)\n","print(x_train.shape, x_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3is6apnw8SIr","colab_type":"text"},"source":["## GANの各設定\n","GANに必要な各設定を行います。"]},{"cell_type":"code","metadata":{"id":"n6Ts3siI8awo","colab_type":"code","colab":{}},"source":["n_learn = 10001 # 学習回数\n","interval = 1000  # 画像を生成する間隔\n","batch_size = 32\n","n_noize = 128  # ノイズの数\n","img_size = 28  # 生成される画像の高さと幅\n","alpha = 0.2  # Leaky ReLUの負の領域での傾き\n","\n","from keras.optimizers import Adam\n","optimizer = Adam(0.0002, 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-esctn70T1mO","colab_type":"text"},"source":["## Generatorの構築\n","以下のページを参考に、  \n","https://keras.io/ja/layers/normalization/  \n","Generaotrにバッチ正規化層を挿入しましょう。  "]},{"cell_type":"code","metadata":{"id":"v_ciGlBGT8nP","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, LeakyReLU, BatchNormalization\n","\n","# 以下のモデルにBatchNormalization層を挿入しましょう \n","generator = Sequential()\n","generator.add(Dense(256, input_shape=(n_noize,)))\n","generator.add(LeakyReLU(alpha=alpha))\n","generator.add(Dense(512))\n","generator.add(LeakyReLU(alpha=alpha)) \n","generator.add(Dense(1024))\n","generator.add(LeakyReLU(alpha=alpha)) \n","generator.add(Dense(img_size**2, activation=\"tanh\"))\n","print(generator.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MtA6l8bpD9rw","colab_type":"text"},"source":["## Discriminatorの構築\n","KerasによりDiscriminatorのモデルを構築します。  "]},{"cell_type":"code","metadata":{"id":"YKqGNtX2D97k","colab_type":"code","colab":{}},"source":["# Discriminatorのネットワーク構築\n","discriminator = Sequential()\n","discriminator.add(Dense(512, input_shape=(img_size**2,)))\n","discriminator.add(LeakyReLU(alpha=alpha)) \n","discriminator.add(Dense(256))\n","discriminator.add(LeakyReLU(alpha=alpha)) \n","discriminator.add(Dense(1, activation=\"sigmoid\"))\n","discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","print(discriminator.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rDIZcbTquuZJ","colab_type":"text"},"source":["## モデルの結合\n","GeneratorとDiscriminatorを結合したモデルを作ります。  "]},{"cell_type":"code","metadata":{"id":"IpqjVvmIu0Fe","colab_type":"code","colab":{}},"source":["from keras.models import Model\n","from keras.layers import Input\n","\n","# 結合時はGeneratorのみ訓練する\n","discriminator.trainable = False\n","\n","# Generatorによってノイズから生成された画像を、Discriminatorが判定する\n","noise = Input(shape=(n_noize,))\n","img = generator(noise)\n","reality = discriminator(img)\n","\n","# GeneratorとDiscriminatorの結合\n","combined = Model(noise, reality)\n","combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n","print(combined.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5g9GMvDQ2BiH","colab_type":"text"},"source":["## 画像の生成\n","Generatorにより、ノイズから画像を生成する関数を定義します。"]},{"cell_type":"code","metadata":{"id":"LkTynUy52nGP","colab_type":"code","colab":{}},"source":["def generate_images(i):\n","    n_rows = 5  # 行数\n","    n_cols = 5  # 列数\n","    noise = np.random.normal(0, 1, (n_rows*n_cols, n_noize))\n","    g_imgs = generator.predict(noise)\n","    g_imgs = g_imgs/2 + 0.5  # 0-1の範囲にする\n","\n","    matrix_image = np.zeros((img_size*n_rows, img_size*n_cols))  # 全体の画像\n","\n","    #  生成された画像を並べて一枚の画像にする\n","    for r in range(n_rows):\n","        for c in range(n_cols):\n","            g_img = g_imgs[r*n_cols + c].reshape(img_size, img_size)\n","            matrix_image[r*img_size : (r+1)*img_size, c*img_size: (c+1)*img_size] = g_img\n","\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(matrix_image, cmap=\"Greys_r\")\n","    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  # 軸目盛りのラベルと線を消す\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oi7x7Jq7ClJ3","colab_type":"text"},"source":["## 学習\n","構築したGANのモデルを使って、学習を行います。  \n","バッチ正規化により、結果がどう変化するのか確認しましょう。  \n","学習には時間がかかりますので、なるべくGPUを使いましょう。"]},{"cell_type":"code","metadata":{"id":"YLUmJ17uDNMl","colab_type":"code","colab":{}},"source":["batch_half = batch_size // 2\n","\n","loss_record = np.zeros((n_learn, 3))\n","acc_record = np.zeros((n_learn, 2))\n","\n","for i in range(n_learn):\n","    \n","    # ノイズから画像を生成しDiscriminatorを訓練\n","    g_noise = np.random.normal(0, 1, (batch_half, n_noize))\n","    g_imgs = generator.predict(g_noise)\n","    loss_fake, acc_fake = discriminator.train_on_batch(g_imgs, np.zeros((batch_half, 1)))\n","    loss_record[i][0] = loss_fake\n","    acc_record[i][0] = acc_fake\n","\n","    # 本物の画像を使ってDiscriminatorを訓練\n","    rand_ids = np.random.randint(len(x_train), size=batch_half)\n","    real_imgs = x_train[rand_ids, :]\n","    loss_real, acc_real = discriminator.train_on_batch(real_imgs, np.ones((batch_half, 1)))\n","    loss_record[i][1] = loss_real\n","    acc_record[i][1] = acc_real\n","\n","    # 結合したモデルによりGeneratorを訓練する\n","    c_noise = np.random.normal(0, 1, (batch_size, n_noize))\n","    loss_comb = combined.train_on_batch(c_noise, np.ones((batch_size, 1)))\n","    loss_record[i][2] = loss_comb\n","\n","    # 一定間隔で生成された画像を表示\n","    if i % interval == 0:\n","        print (\"n_learn:\", i)\n","        print (\"loss_fake:\", loss_fake, \"acc_fake:\", acc_fake)\n","        print (\"loss_real:\", loss_real, \"acc_real:\", acc_real)\n","        print (\"loss_comb:\", loss_comb)\n","\n","        generate_images(i)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ah8Ou20kWq6","colab_type":"text"},"source":["学習がうまく進まないこともありますので、その際はモデル構築のセルから再実行しましょう。  "]},{"cell_type":"markdown","metadata":{"id":"qJNVTqaMdS5g","colab_type":"text"},"source":["## 誤差と精度の推移\n","各誤差の収束と、Discriminatorの精度の向上を確認します。"]},{"cell_type":"code","metadata":{"id":"RL_wMuxedbil","colab_type":"code","colab":{}},"source":["# 誤差の推移\n","n_plt_loss = 500\n","plt.plot(np.arange(n_plt_loss), loss_record[:n_plt_loss, 0], label=\"loss_fake\")\n","plt.plot(np.arange(n_plt_loss), loss_record[:n_plt_loss, 1], label=\"loss_real\")\n","plt.plot(np.arange(n_plt_loss), loss_record[:n_plt_loss, 2], label=\"loss_comb\")\n","plt.legend()\n","plt.title(\"Loss\")\n","plt.show()\n","\n","# 精度の推移\n","n_plt_acc = 1000\n","plt.plot(np.arange(n_plt_acc), acc_record[:n_plt_acc, 0], label=\"acc_fake\")\n","plt.plot(np.arange(n_plt_acc), acc_record[:n_plt_acc, 1], label=\"acc_real\")\n","plt.legend()\n","plt.title(\"Accuracy\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OetFBzcZkvSB","colab_type":"text"},"source":["# 解答例\n","以下は解答例です。  \n","どうしてもわからない時のみ、参考にしましょう。  \n"]},{"cell_type":"code","metadata":{"id":"v70hv96UnpSe","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, LeakyReLU, BatchNormalization\n","\n","# Generatorのネットワーク構築\n","generator = Sequential()\n","generator.add(Dense(256, input_shape=(n_noize,)))\n","generator.add(LeakyReLU(alpha=alpha))\n","generator.add(BatchNormalization())\n","generator.add(Dense(512))\n","generator.add(LeakyReLU(alpha=alpha)) \n","generator.add(BatchNormalization())\n","generator.add(Dense(1024))\n","generator.add(LeakyReLU(alpha=alpha)) \n","generator.add(BatchNormalization())\n","generator.add(Dense(img_size**2, activation=\"tanh\"))\n","print(generator.summary())"],"execution_count":null,"outputs":[]}]}