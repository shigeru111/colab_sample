{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gan.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"K74mqS_L8nq4","colab_type":"text"},"source":["# GANの実装\n","GAN（敵対的生成ネットワーク）を実装します。  \n","GANにより、手書き文字画像を生成しましょう。"]},{"cell_type":"markdown","metadata":{"id":"AAYDnNlPJ46Z","colab_type":"text"},"source":["## 訓練用データの用意\n","GANに用いる訓練用のデータを用意します。  \n","MNIST（手書き文字）のデータを読み込み、最初の画像を表示します。  \n","今回は、各ピクセルの値はGeneratorの活性化関数に合わせて-１から1の範囲に収まるように調整します。  "]},{"cell_type":"code","metadata":{"id":"EcKpe2k38bax","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt \n","from keras.datasets import mnist\n","\n","(x_train, t_train), (x_test, t_test) = mnist.load_data()  # MNISTの読み込み\n","print(x_train.shape, x_test.shape)  # 28x28の手書き文字画像が6万枚\n","\n","# 各ピクセルの値を-1から1の範囲に収める\n","x_train = x_train / 255 * 2 - 1\n","x_test = x_test / 255 * 2 - 1\n","\n","# 手書き文字画像の表示\n","plt.imshow(x_train[0].reshape(28, 28), cmap=\"gray\")\n","plt.title(t_train[0])\n","plt.show() \n","\n","# 一次元に変換する\n","x_train = x_train.reshape(x_train.shape[0], -1)\n","x_test = x_test.reshape(x_test.shape[0], -1)\n","print(x_train.shape, x_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3is6apnw8SIr","colab_type":"text"},"source":["## GANの各設定\n","GANに必要な各設定を行います。  \n","Generatorに入力するノイズの数はここで設定します。  \n","最適化アルゴリズムにはパラメータを調整したAdamを使用します。  "]},{"cell_type":"code","metadata":{"id":"n6Ts3siI8awo","colab_type":"code","colab":{}},"source":["n_learn = 10001 # 学習回数\n","interval = 1000  # 画像を生成する間隔\n","batch_size = 32\n","n_noize = 128  # ノイズの数\n","img_size = 28  # 生成される画像の高さと幅\n","alpha = 0.2  # Leaky ReLUの負の領域での傾き\n","\n","from keras.optimizers import Adam\n","optimizer = Adam(0.0002, 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-esctn70T1mO","colab_type":"text"},"source":["## Generatorの構築\n","KerasによりGeneratorのモデルを構築します。  \n","中間層の活性化関数にはLeaky ReLUを使用します。  \n","Leaky ReLUは、ReLUが負の領域でも小さな傾きを持ったもので、以下の式で表されます。\n","\n","$$\n","y = \\left\\{\n","\\begin{array}{ll}\n","\\alpha x & (x \\leqq 0)\\\\\n","x & (x > 0)\n","\\end{array}\n","\\right.\n","$$ \n","\n","$\\alpha$には通常0.01などの小さな値が使われます。  \n","ReLUでは、出力が0になって学習が進まないニューロンが多数出現する、dying ReLUという現象が知られています。  \n","Leaky ReLUは、負の領域にわずかに傾きをつけることによって、このdying ReLUの問題を回避できると考えられています。  \n","GANではGeneratorで勾配が消失しやすく学習が停滞するので、$\\alpha$の値を大きめにしたLeaky ReLUがしばしば使われます。"]},{"cell_type":"code","metadata":{"id":"v_ciGlBGT8nP","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, LeakyReLU\n","\n","# Generatorのネットワーク構築\n","generator = Sequential()\n","generator.add(Dense(256, input_shape=(n_noize,)))\n","generator.add(LeakyReLU(alpha=alpha)) \n","generator.add(Dense(512))\n","generator.add(LeakyReLU(alpha=alpha)) \n","generator.add(Dense(1024))\n","generator.add(LeakyReLU(alpha=alpha)) \n","generator.add(Dense(img_size**2, activation=\"tanh\"))\n","print(generator.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w6537DznbR_T","colab_type":"text"},"source":["出力層の活性化関数には、Discriminatorへの入力を-1から1の範囲にするためにtanhを使います。  \n","Generator単独で学習することはないので、この段階でコンパイルする必要はありません。"]},{"cell_type":"markdown","metadata":{"id":"MtA6l8bpD9rw","colab_type":"text"},"source":["## Discriminatorの構築\n","KerasによりDiscriminatorのモデルを構築します。  \n","中間層の活性化関数にはGeneratorと同じくLeaky ReLUを使い、出力層の活性化関数には0から1の値で本物かどうかを識別するためにsigmoid関数を使います。  \n","損失関数には、出力と正解の範囲が0から1の場合使用可能で、収束しやすい二値の交差エントロピーを使用します。  "]},{"cell_type":"code","metadata":{"id":"YKqGNtX2D97k","colab_type":"code","colab":{}},"source":["# Discriminatorのネットワーク構築\n","discriminator = Sequential()\n","discriminator.add(Dense(512, input_shape=(img_size**2,)))\n","discriminator.add(LeakyReLU(alpha=alpha)) \n","discriminator.add(Dense(256))\n","discriminator.add(LeakyReLU(alpha=alpha)) \n","discriminator.add(Dense(1, activation=\"sigmoid\"))\n","discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","print(discriminator.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uh7R-D7nc6V-","colab_type":"text"},"source":["Discriminatorは単独で学習を行うので、コンパイルする必要があります。"]},{"cell_type":"markdown","metadata":{"id":"rDIZcbTquuZJ","colab_type":"text"},"source":["## モデルの結合\n","GeneratorとDiscriminatorを結合したモデルを作ります。  \n","ノイズからGeneratorにより画像を生成し、Discriminatorによりそれが本物の画像かどうか判定するように結合を行います。  \n","結合モデルではGeneratorのみ訓練するので、Discriminatorは訓練しないように設定します。"]},{"cell_type":"code","metadata":{"id":"IpqjVvmIu0Fe","colab_type":"code","colab":{}},"source":["from keras.models import Model\n","from keras.layers import Input\n","\n","# 結合時はGeneratorのみ訓練する\n","discriminator.trainable = False\n","\n","# Generatorによってノイズから生成された画像を、Discriminatorが判定する\n","noise = Input(shape=(n_noize,))\n","img = generator(noise)\n","reality = discriminator(img)\n","\n","# GeneratorとDiscriminatorの結合\n","combined = Model(noise, reality)\n","combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n","print(combined.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5g9GMvDQ2BiH","colab_type":"text"},"source":["## 画像の生成\n","Generatorにより、ノイズから画像を生成する関数を定義します。"]},{"cell_type":"code","metadata":{"id":"LkTynUy52nGP","colab_type":"code","colab":{}},"source":["def generate_images(i):\n","    n_rows = 5  # 行数\n","    n_cols = 5  # 列数\n","    noise = np.random.normal(0, 1, (n_rows*n_cols, n_noize))\n","    g_imgs = generator.predict(noise)\n","    g_imgs = g_imgs/2 + 0.5  # 0-1の範囲にする\n","\n","    matrix_image = np.zeros((img_size*n_rows, img_size*n_cols))  # 全体の画像\n","\n","    #  生成された画像を並べて一枚の画像にする\n","    for r in range(n_rows):\n","        for c in range(n_cols):\n","            g_img = g_imgs[r*n_cols + c].reshape(img_size, img_size)\n","            matrix_image[r*img_size : (r+1)*img_size, c*img_size: (c+1)*img_size] = g_img\n","\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(matrix_image, cmap=\"Greys_r\")\n","    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  # 軸目盛りのラベルと線を消す\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oi7x7Jq7ClJ3","colab_type":"text"},"source":["## 学習\n","構築したGANのモデルを使って、学習を行います。  \n","Generatorが生成した画像には正解ラベル0、本物の画像には正解ラベル1を与えてDiscriminatorを訓練します。  \n","その後に、結合したモデルを使ってGeneratorを訓練しますが、この場合の正解ラベルは1になります。  \n","これらの訓練を繰り返すことで、本物と見分けがつかない手書き文字画像が生成されるようになります。  \n","また、学習には時間がかかりますので、なるべくGPUを使いましょう。"]},{"cell_type":"code","metadata":{"id":"YLUmJ17uDNMl","colab_type":"code","colab":{}},"source":["batch_half = batch_size // 2\n","\n","loss_record = np.zeros((n_learn, 3))\n","acc_record = np.zeros((n_learn, 2))\n","\n","for i in range(n_learn):\n","    \n","    # ノイズから画像を生成しDiscriminatorを訓練\n","    g_noise = np.random.normal(0, 1, (batch_half, n_noize))\n","    g_imgs = generator.predict(g_noise)\n","    loss_fake, acc_fake = discriminator.train_on_batch(g_imgs, np.zeros((batch_half, 1)))\n","    loss_record[i][0] = loss_fake\n","    acc_record[i][0] = acc_fake\n","\n","    # 本物の画像を使ってDiscriminatorを訓練\n","    rand_ids = np.random.randint(len(x_train), size=batch_half)\n","    real_imgs = x_train[rand_ids, :]\n","    loss_real, acc_real = discriminator.train_on_batch(real_imgs, np.ones((batch_half, 1)))\n","    loss_record[i][1] = loss_real\n","    acc_record[i][1] = acc_real\n","\n","    # 結合したモデルによりGeneratorを訓練する\n","    c_noise = np.random.normal(0, 1, (batch_size, n_noize))\n","    loss_comb = combined.train_on_batch(c_noise, np.ones((batch_size, 1)))\n","    loss_record[i][2] = loss_comb\n","\n","    # 一定間隔で生成された画像を表示\n","    if i % interval == 0:\n","        print (\"n_learn:\", i)\n","        print (\"loss_fake:\", loss_fake, \"acc_fake:\", acc_fake)\n","        print (\"loss_real:\", loss_real, \"acc_real:\", acc_real)\n","        print (\"loss_comb:\", loss_comb)\n","\n","        generate_images(i)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ah8Ou20kWq6","colab_type":"text"},"source":["学習がうまく進まないこともありますので、その際はモデル構築のセルから再実行しましょう。  "]},{"cell_type":"markdown","metadata":{"id":"qJNVTqaMdS5g","colab_type":"text"},"source":["## 誤差と精度の推移\n","各誤差の収束と、Discriminatorの精度の向上を確認します。"]},{"cell_type":"code","metadata":{"id":"RL_wMuxedbil","colab_type":"code","colab":{}},"source":["# 誤差の推移\n","n_plt_loss = 500\n","plt.plot(np.arange(n_plt_loss), loss_record[:n_plt_loss, 0], label=\"loss_fake\")\n","plt.plot(np.arange(n_plt_loss), loss_record[:n_plt_loss, 1], label=\"loss_real\")\n","plt.plot(np.arange(n_plt_loss), loss_record[:n_plt_loss, 2], label=\"loss_comb\")\n","plt.legend()\n","plt.title(\"Loss\")\n","plt.show()\n","\n","# 精度の推移\n","n_plt_acc = 1000\n","plt.plot(np.arange(n_plt_acc), acc_record[:n_plt_acc, 0], label=\"acc_fake\")\n","plt.plot(np.arange(n_plt_acc), acc_record[:n_plt_acc, 1], label=\"acc_real\")\n","plt.legend()\n","plt.title(\"Accuracy\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OetFBzcZkvSB","colab_type":"text"},"source":["学習がうまく進んでいれば、均衡点でバランスがとられるナッシュ均衡が出現します。"]}]}